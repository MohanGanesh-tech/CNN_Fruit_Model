{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from skimage.transform import resize\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tensorflow: \",tf.__version__,\"\\n\")\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "from tensorflow.python.client import device_lib\n",
    "print(\"Device avialable to Tensorflow: \\n\\n\",device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR=os.getcwd()\n",
    "dataset_dir=os.path.join(BASE_DIR,\"Dataset\")\n",
    "categories=os.listdir(dataset_dir)\n",
    "print(dataset_dir,\"\\n\",categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "IMG_SIZE = 100\n",
    "def create_training_data():\n",
    "    count = 0\n",
    "    for category in categories:\n",
    "        path = os.path.join(dataset_dir,category)\n",
    "        class_num = categories.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE,IMG_SIZE))\n",
    "                training_data.append([new_array,class_num])\n",
    "                count = count+1\n",
    "                print(count)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "            \n",
    "create_training_data()\n",
    "print(\"\\n \\n Total Traning Data Length\",len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for features,labels in training_data:\n",
    "    X.append(features)\n",
    "    y.append(labels)\n",
    "    \n",
    "X = np.array(X).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(\"X.pickle\",\"wb\")\n",
    "pickle.dump(X,pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y.pickle\",\"wb\")\n",
    "pickle.dump(y,pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "del X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "X = pickle.load(open(\"X.pickle\",\"rb\"))\n",
    "y = pickle.load(open(\"y.pickle\",\"rb\"))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_test_one_hot = to_categorical(y_test)\n",
    "\n",
    "del labels,features,y_train,y_test,X,y\n",
    "\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3,3), input_shape = x_train.shape[1:],activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64,3,3, activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128,activation= 'relu'))\n",
    "\n",
    "model.add(Dense(64,activation= 'relu'))\n",
    "model.add(Dense(len(categories), activation='softmax'))\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\",optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "hist = model.fit(x_train, y_train_one_hot,batch_size=50, epochs=5, validation_split=0.3 )\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.evaluate(x_test, y_test_one_hot)[1]\n",
    "\n",
    "history_dict = hist.history\n",
    "print(history_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['acc'])\n",
    "plt.plot(hist.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_add='C:/Users/Ganesh/Desktop/Final/Test/r_8_100.jpg'\n",
    "my_image = plt.imread(image_add)\n",
    "plt.imshow(my_image)\n",
    "my_image_resized = resize(my_image, (IMG_SIZE,IMG_SIZE,1))\n",
    "probabilities = model.predict(np.array( [my_image_resized,] ))\n",
    "\n",
    "index = np.argsort(probabilities[0,:])\n",
    "print(\"Predicted Class:\", categories[index[len(categories)-1]],\"\\nProbability:\", probabilities[0,index[len(categories)-1]]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
